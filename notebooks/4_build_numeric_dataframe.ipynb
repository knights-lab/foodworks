{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas  1.1.4\n",
      "numpy   1.19.5\n",
      "seaborn 0.11.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(930525)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "warnings.simplefilter('once')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhillmann/.conda/envs/type_1/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.txt\", sep=\"\\t\", index_col=0)\n",
    "train_warp = pd.read_csv(\"../data/train.warp.txt\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out columns that are correlated\n",
    "s_cols = set([\"tax\", \"food\", \"kegg\", \"nutrients\"])\n",
    "s_cols_response = set([\"day_plus_one\"])\n",
    "s_cont_cols = set([\"Age\", \"Weight\", \"Height\", \"BMI\", \"oilGrams.assigned\", \"Activity.Factor\", \"StudyDayNo\"])\n",
    "df_numeric = train[[col for col in train.columns if col.split(\".\")[0] in s_cols or col in s_cont_cols]]\n",
    "df_response = train[[col for col in train.columns if col.split(\".\")[0] in s_cols_response]]\n",
    "df_binary = train[[col for col in train.columns if (col.split(\".\")[0] not in s_cols.union(s_cols_response) and col not in s_cont_cols) and col != \"Timing\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary.to_csv(\"../data/prediction.train.binary.txt\", sep=\"\\t\")\n",
    "df_response.to_csv(\"../data/prediction.train.response.txt\", sep=\"\\t\")\n",
    "df_numeric.to_csv(\"../data/prediction.train.numeric.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out columns that are correlated\n",
    "s_cols = set([\"tax\", \"food\", \"kegg\", \"nutrients\"])\n",
    "s_cols_response = set([\"day_plus_one\"])\n",
    "s_cont_cols = set([\"Age\", \"Weight\", \"Height\", \"BMI\", \"oilGrams.assigned\", \"Activity.Factor\", \"StudyDayNo\"])\n",
    "df_numeric_warp = train_warp[[col for col in train_warp.columns if col.split(\".\")[0] in s_cols or col in s_cont_cols]]\n",
    "df_response_warp = train_warp[[col for col in train_warp.columns if col.split(\".\")[0] in s_cols_response]]\n",
    "df_binary_warp = train_warp[[col for col in train_warp.columns if (col.split(\".\")[0] not in s_cols.union(s_cols_response) and col not in s_cont_cols) and col != \"Timing\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary_warp.to_csv(\"../data/prediction.train.binary.warp.txt\", sep=\"\\t\")\n",
    "df_response_warp.to_csv(\"../data/prediction.train.response.warp.txt\", sep=\"\\t\")\n",
    "df_numeric_warp.to_csv(\"../data/prediction.train.numeric.warp.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day_plus_one.tax.k__Bacteria.p__Firmicutes_A.c__Clostridia.o__Lachnospirales.f__Lachnospiraceae.g__CAG_882.s__CAG_882_sp003486385',\n",
       " 'day_plus_one.tax.k__Bacteria.p__Firmicutes_A.c__Clostridia.o__Oscillospirales.f__Oscillospiraceae.g__CAG_83.s__CAG_83_sp000435555',\n",
       " 'day_plus_one.tax.k__Bacteria.p__Firmicutes_A.c__Clostridia_A.o__Christensenellales.f__CAG_74.g__UBA11524.s__UBA11524_sp000437595',\n",
       " 'day_plus_one.tax.k__Bacteria.p__Firmicutes_A.c__Clostridia_A.o__Christensenellales.f__CAG_917.g__CAG_349.s__CAG_349_sp003539515',\n",
       " 'day_plus_one.tax.k__Bacteria.p__Firmicutes_A.c__Clostridia_A.o__Christensenellales.f__CAG_917.g__CAG_475.s__CAG_475_sp000434435',\n",
       " 'day_plus_one.tax.k__Bacteria.p__Proteobacteria.c__Alphaproteobacteria.o__RF32.f__CAG_239.g__CAG_495.s__CAG_495_sp000436375']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in df_response_warp.columns if \"CAG\" in _]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-type_1]",
   "language": "python",
   "name": "conda-env-.conda-type_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
